{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Word Cloud Challenge\n",
    "\n",
    "We are going to be getting data from Twitter, cleaning it and using the search results to generate a word cloud! We will be using the library `snscrape` to get data from Twitter and `stylecloud` to generate the word cloud!\n",
    "\n",
    "## Requirement file\n",
    "\n",
    "Luckily the environment has all the packages you need already installed but we will list them here anyway!\n",
    "\n",
    "```\n",
    "stylecloud\n",
    "git+https://github.com/JustAnotherArchivist/snscrape.git # snscrape from git as Twitter recently introduced breaking changes\n",
    "pandas\n",
    "matplotlib\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON\n",
    "\n",
    "A way to store data (lists, dictionaries, etc) in a string or file format. An example and exercise is below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_example = r'''\n",
    "{\n",
    "  \"url\": \"https://twitter.com/ChicagoPython/status/1309180179537952771\",\n",
    "  \"date\": \"2020-09-24T17:17:32+00:00\",\n",
    "  \"content\": \"Get off Twitter!! Join the Chicago Python Livestream on MLOps!\\n\\n#Python  #MLOps #DataOps #PythonLunchBreak #ChiPy #100DaysOfCode #100DaysOfMLCode \\n\\nhttps://t.co/7EKjBEvsc0\",\n",
    "  \"renderedContent\": \"Get off Twitter!! Join the Chicago Python Livestream on MLOps!\\n\\n#Python  #MLOps #DataOps #PythonLunchBreak #ChiPy #100DaysOfCode #100DaysOfMLCode \\n\\nyoutube.com/watch?v=uClvvl‚Ä¶\",\n",
    "  \"id\": 1309180179537952800,\n",
    "  \"username\": \"ChicagoPython\",\n",
    "  \"user\": {\n",
    "    \"username\": \"ChicagoPython\",\n",
    "    \"displayname\": \"ChiPy\",\n",
    "    \"id\": 4145734157,\n",
    "    \"description\": \"The Chicago Python User Group loves you! üêø\\n\\nYouTube: bit.ly/chipy-tube\\nUpcoming events: meetup.com/_ChiPy_/\",\n",
    "    \"rawDescription\": \"The Chicago Python User Group loves you! üêø\\n\\nYouTube: https://t.co/WzOFvxLloJ\\nUpcoming events: https://t.co/qDHRHyxbGW\",\n",
    "    \"descriptionUrls\": [\n",
    "      {\n",
    "        \"text\": \"bit.ly/chipy-tube\",\n",
    "        \"url\": \"http://bit.ly/chipy-tube\",\n",
    "        \"tcourl\": \"https://t.co/WzOFvxLloJ\",\n",
    "        \"indices\": [\n",
    "          53,\n",
    "          76\n",
    "        ]\n",
    "      },\n",
    "      {\n",
    "        \"text\": \"meetup.com/_ChiPy_/\",\n",
    "        \"url\": \"http://meetup.com/_ChiPy_/\",\n",
    "        \"tcourl\": \"https://t.co/qDHRHyxbGW\",\n",
    "        \"indices\": [\n",
    "          94,\n",
    "          117\n",
    "        ]\n",
    "      }\n",
    "    ],\n",
    "    \"verified\": false,\n",
    "    \"created\": \"2015-11-09T01:26:26+00:00\",\n",
    "    \"followersCount\": 1467,\n",
    "    \"friendsCount\": 1139,\n",
    "    \"statusesCount\": 1325,\n",
    "    \"favouritesCount\": 634,\n",
    "    \"listedCount\": 33,\n",
    "    \"mediaCount\": 304,\n",
    "    \"location\": \"Chicago, IL\",\n",
    "    \"protected\": false,\n",
    "    \"linkUrl\": \"http://www.chipy.org\",\n",
    "    \"linkTcourl\": \"https://t.co/PRcBbqRkpO\",\n",
    "    \"profileImageUrl\": \"https://pbs.twimg.com/profile_images/663559306965454848/aBTV9K8l_normal.png\",\n",
    "    \"profileBannerUrl\": \"https://pbs.twimg.com/profile_banners/4145734157/1447037423\"\n",
    "  },\n",
    "  \"outlinks\": [\n",
    "    \"https://www.youtube.com/watch?v=uClvvlfJxqo\"\n",
    "  ],\n",
    "  \"outlinksss\": \"https://www.youtube.com/watch?v=uClvvlfJxqo\",\n",
    "  \"tcooutlinks\": [\n",
    "    \"https://t.co/7EKjBEvsc0\"\n",
    "  ],\n",
    "  \"tcooutlinksss\": \"https://t.co/7EKjBEvsc0\",\n",
    "  \"replyCount\": 0,\n",
    "  \"retweetCount\": 3,\n",
    "  \"likeCount\": 1,\n",
    "  \"quoteCount\": 0,\n",
    "  \"conversationId\": 1309180179537952800,\n",
    "  \"lang\": \"en\",\n",
    "  \"source\": \"<a href=\\\"https://mobile.twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web App</a>\",\n",
    "  \"media\": null,\n",
    "  \"retweetedTweet\": null,\n",
    "  \"quotedTweet\": null,\n",
    "  \"mentionedUsers\": null\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "Load the JSON example above (don't forget to run the cell) using the `json.loads()` function. Remember, this will turn the json into a python dictionary. Now use it to find the following  information from the tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON example text from above\n",
    "# INSERT CODE HERE\n",
    "\n",
    "\n",
    "# Print how many times the tweet was retweeted aka the \"retweetCount\"\n",
    "# INSERT CODE HERE\n",
    "\n",
    "\n",
    "# Print the link to the meetup from the tweet information\n",
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2\n",
    "\n",
    "Write a function that takes loads example JSON string above and returns the retweet count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your function here\n",
    "# INSERT CODE HERE\n",
    "\n",
    "print(get_retweet_count(json_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading JSON to a file\n",
    "\n",
    "Many times it's not convenient to keep on hitting a URL for a JSON, maybe the website is too slow or there is a limit on how many times a user can access it. In these cases, it's best to save the JSON to a file and read it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the JSON to a file named 'example.json'\n",
    "\n",
    "# INSERT CODE HERE\n",
    "\n",
    "# Load the JSON back from 'example.json' (using json.load)\n",
    "\n",
    "# INSERT CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is an API?\n",
    "\n",
    "An API (Application Programmer Interface) is a way a website/app allows a user to programmatically access data.\n",
    "\n",
    "## Other ways of accessing data\n",
    "\n",
    "1. Copying and pasting data into a spreadsheet (or plain text file) and reading with Python package `csv` or `pandas` (or if it's a text file, then loop through the lines) \n",
    "\n",
    "1. Scraping/parsing the HTML with Python package *Beautiful Soup* (or equivalent)\n",
    "\n",
    "## API vs. Other Methods\n",
    "\n",
    "An API is more organized and the way the app wants you to access its data. However many websites or apps don't have an API, or it is too poorly designed. In those cases, it's better to use a more crude approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Twitter Unofficial API\n",
    "\n",
    "We will be using an unofficial API to get data called `snscrape`. Typically it is better to use an official API, but we are limited for this challenge to less than two hours. The setup for the official API is more involved and may take up to 24 hours to actually get the API key emailed to you.\n",
    "\n",
    "The following is a helper function to load the json output command line utility snscrape into a python dictionary. We will be using it to scrape Twitter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def snscrape(commands):\n",
    "    result = subprocess.run(['snscrape', '--jsonl'] + commands, stdout=subprocess.PIPE)\n",
    "    data = result.stdout.decode('utf-8')\n",
    "    results = [json.loads(jline) for jline in data.splitlines()] # jsonl to json parsed\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to search Twitter. Luckily the library snscrape and the code above will do the heavy lifting!\n",
    "\n",
    "## Exercise 4\n",
    "\n",
    "Play around with the following api commands `twitter-search` `twitter-user` and `twitter-hashtag`. Feel free to get creative with your searches! Print and see what your tweets look like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tweets = snscrape(['--max-results', '1000', 'twitter-search','python chicago'])\n",
    "#tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snscrape(['--max-results', '2', 'twitter-user','chicagopython'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snscrape(['--max-results', '2', 'twitter-hashtag','YOLO'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "\n",
    "Unfortunately as you can notice there are a bunch of `https://t.co/xzzzX34xz` URLs and we don't want those there. Write code to remove the URLS with a regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_urls(tweets):\n",
    "    for tweet in tweets:\n",
    "        content = tweet['content']\n",
    "        tweet['content'] = re.sub(r'# INSERT_CODE_HERE', '', content)\n",
    "    return tweets\n",
    "\n",
    "tweets = remove_urls(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6\n",
    "\n",
    "Unfortunately as you can notice many of the tweets are duplicated. Write code to remove duplicates using a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(tweets):\n",
    "    # INSERT CODE HERE\n",
    "    for tweet in tweets:\n",
    "        # INSERT CODE HERE\n",
    "    return # INSERT CODE HERE\n",
    "\n",
    "print(\"NUMBER TWEETS WITH DUPLICATES: {}\".format(len(tweets)))\n",
    "tweets = remove_duplicates(tweets)\n",
    "print(\"NUMBER TWEETS WITHOUT DUPLICATES: {}\".format(len(tweets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 7\n",
    "\n",
    "We would to further process all tweets in one string without any other junk. Collect all the tweets into one python lowercased string. Use the sample code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ''\n",
    "for tweet in tweets:\n",
    "    corpus = # INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 8\n",
    "\n",
    "We are going to convert the tweets into text a few times so we can process the next from different searches. Since we don't want to repeat ourself, write a function below that does the following:\n",
    "\n",
    "- Given the search string, it returns the text from all the results as we found above. \n",
    "- Adds the code to remove URLs and duplicates\n",
    "- Be sure to remove URLS first before removing duplicates. (Twitter adds random characters to links.)\n",
    "- Don't forget to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_search(query_data):\n",
    "    # INSERT CODE HERE\n",
    "    return corpus\n",
    "    \n",
    "corpus = get_text_from_search(\"python chicago\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Cloud\n",
    "\n",
    "Now that we have some tweet results, we are going to collect all the text into one python string so we can make a word cloud\n",
    "\n",
    "There are few python libraries that convert text to a word cloud. This one allows us to specify any shape from https://fontawesome.com/ so we will use the twitter logo. Run the code below to see it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import stylecloud\n",
    "from IPython.display import Image\n",
    "import os\n",
    "\n",
    "filename = 'wordcloud.png'\n",
    "\n",
    "stylecloud.gen_stylecloud(text=corpus, icon_name='fab fa-twitter', output_name=filename)\n",
    "Image(filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 10\n",
    "\n",
    "Unfortunately our word cloud is not perfect. First of all our words that we searched for are showing up. We are searching for them so they are gonna have to be present. We need to remove the words we searched for.\n",
    "\n",
    "Second there is this `amp` showing up that is not a real word. This is actually due to the `&` and it is converted to the word. See if you can modify the function we made to remove that and the search terms and try again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 11\n",
    "\n",
    "See if you can look at the `stylecloud` documentation here https://github.com/minimaxir/stylecloud and play around with the shape of the word cloud or the different paramaters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 12\n",
    "\n",
    "Many times the sites we are interested in analyzing data from, do not have apis. Can you generate the word cloud using a more crude method? (Hint: One way is to copy and paste the text from twitter into a string and then pass that into the word cloud.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_from_website ='''\n",
    "???\n",
    "'''\n",
    "\n",
    "stylecloud.gen_stylecloud(text=text_from_website, icon_name='fab fa-twitter', output_name=filename)\n",
    "#Image(filename=filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning and Analysis\n",
    "\n",
    "Now we will do some more cleaning to the text. We didn't have to as much before because the wordlcoud package did that for you. However, now since we are doing a more specific analysis, we will have to clean the data.\n",
    "\n",
    "## Exercise 13\n",
    "\n",
    "Can you use a regular expression to strip non alphabet characters? What about replacing new lines with spaces (regular expression not needed for this part)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE\n",
    "corpus_no_chars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bar Plot\n",
    "\n",
    "We will now count the number of words in the twitter searches, and visualize the results! For example we want to see how often people are tweeting about politicians.  However first we need to create a function to count the word occurances.\n",
    "\n",
    "## Exercise 14\n",
    "\n",
    "Make a function that given the tweet text and a word, it cleans the text (using the code above) and counts the occurance of that word.\n",
    "\n",
    "Use `str.count` to count the words. For example `'hello world'.count('hello')` will return `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_count(tweet_text, word):\n",
    "    tweet_text = tweet_text.lower()\n",
    "    # INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 15\n",
    "\n",
    "We would like to make a bar plot similar to the below except with real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {'place':['chicago', 'detroit'], 'biden':[4,3], 'trump':[3,5]}\n",
    "df = pd.DataFrame(data)\n",
    "df.plot(kind='bar',x='place',y=['biden','trump'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a `dict` to create a pandas dataframe similar to the example above. Use `clean_and_count` and fill the code below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "words = ['biden', 'trump']\n",
    "for word in words:\n",
    "    places = ['chicago', 'texas']\n",
    "    data[word] = [] # Here we initialize the list so we can append to it\n",
    "    data['place'] = places # Here we initilize the places\n",
    "    for place in places:\n",
    "        print(word, place)\n",
    "        search_query = place + ' election'\n",
    "        # INSERT CODE HERE\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "Now we are ready to plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind='bar',x='place',y=words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you think of any other combinations to try?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
